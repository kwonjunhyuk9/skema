[
  {
    "chapter": "Classification",
    "topics": [
      {
        "topic": "MNIST",
        "concepts": [
          "Handwritten digit dataset",
          "Standard benchmark for classifiers",
          "Image preprocessing"
        ]
      },
      {
        "topic": "Training a Binary Classifier",
        "concepts": [
          "Logistic regression",
          "Support Vector Machines",
          "Model fitting and parameter tuning"
        ]
      },
      {
        "topic": "Performance Measurement",
        "concepts": [
          "Evaluating model accuracy",
          "Using metrics beyond accuracy",
          "Cross-validation"
        ]
      },
      {
        "topic": "Cross-Validation for Accuracy Measurement",
        "concepts": [
          "k-fold cross-validation",
          "Train-test splits",
          "Avoiding overfitting"
        ]
      },
      {
        "topic": "Confusion Matrix",
        "concepts": [
          "True positives and negatives",
          "False positives and negatives",
          "Error analysis"
        ]
      },
      {
        "topic": "Precision and Recall",
        "concepts": [
          "Precision: correctness of positive predictions",
          "Recall: coverage of actual positives",
          "Balancing metrics"
        ]
      },
      {
        "topic": "Precision and Recall Trade-off",
        "concepts": [
          "Adjusting decision thresholds",
          "Impact on model performance",
          "F1 score"
        ]
      },
      {
        "topic": "ROC Curve",
        "concepts": [
          "True positive rate vs false positive rate",
          "Area under the curve",
          "Threshold selection"
        ]
      },
      {
        "topic": "Multiclass Classification",
        "concepts": [
          "One-vs-all strategy",
          "One-vs-one strategy",
          "Softmax regression"
        ]
      },
      {
        "topic": "Error Analysis",
        "concepts": [
          "Inspecting misclassified examples",
          "Finding patterns of mistakes",
          "Improving model iteratively"
        ]
      },
      {
        "topic": "Multilabel Classification",
        "concepts": [
          "Predicting multiple labels per instance",
          "Binary relevance method",
          "Classifier chains"
        ]
      },
      {
        "topic": "Multi-output Classification",
        "concepts": [
          "Multiple outputs from one input",
          "Joint modeling",
          "Handling dependent outputs"
        ]
      }
    ]
  },
  {
    "chapter": "Model Training",
    "topics": [
      {
        "topic": "Linear Regression",
        "concepts": [
          "Predicting continuous outcomes",
          "Least squares fitting",
          "Regular equation solution",
          "Computational complexity"
        ]
      },
      {
        "topic": "Gradient Descent",
        "concepts": [
          "Iterative optimization",
          "Batch gradient descent",
          "Stochastic gradient descent",
          "Mini-batch gradient descent"
        ]
      },
      {
        "topic": "Polynomial Regression",
        "concepts": [
          "Modeling non-linear relationships",
          "Feature expansion",
          "Overfitting considerations"
        ]
      },
      {
        "topic": "Learning Curves",
        "concepts": [
          "Training vs validation error",
          "Detecting overfitting and underfitting",
          "Model performance visualization"
        ]
      },
      {
        "topic": "Regularized Linear Models",
        "concepts": [
          "Ridge regression",
          "Lasso regression",
          "Elastic Net",
          "Early stopping for regularization"
        ]
      },
      {
        "topic": "Logistic Regression",
        "concepts": [
          "Estimating probabilities",
          "Training with cost function",
          "Decision boundaries",
          "Softmax regression for multiclass"
        ]
      }
    ]
  },
  {
    "chapter": "Decision Trees",
    "topics": [
      {
        "topic": "Learning and Visualization",
        "concepts": [
          "Tree construction from data",
          "Feature splitting",
          "Graphical visualization of trees",
          "Interpreting tree structure"
        ]
      },
      {
        "topic": "Prediction",
        "concepts": [
          "Classifying new instances",
          "Traversing tree paths",
          "Handling unseen feature values"
        ]
      },
      {
        "topic": "Class Probability Estimation",
        "concepts": [
          "Leaf node probability calculation",
          "Soft predictions",
          "Smoothing techniques"
        ]
      },
      {
        "topic": "CART Training Algorithm",
        "concepts": [
          "Classification and Regression Trees",
          "Binary splitting",
          "Recursive partitioning",
          "Impurity-based splits"
        ]
      },
      {
        "topic": "Computational Complexity",
        "concepts": [
          "Time complexity of tree construction",
          "Memory usage",
          "Impact of dataset size"
        ]
      },
      {
        "topic": "Gini Impurity vs Entropy",
        "concepts": [
          "Measuring node impurity",
          "Choosing split criteria",
          "Comparison of Gini and entropy"
        ]
      },
      {
        "topic": "Regularization Parameters",
        "concepts": [
          "Maximum depth",
          "Minimum samples per leaf",
          "Pruning strategies",
          "Preventing overfitting"
        ]
      },
      {
        "topic": "Regression with Decision Trees",
        "concepts": [
          "Predicting continuous values",
          "Mean squared error splitting",
          "Leaf value estimation"
        ]
      },
      {
        "topic": "Axis-Aligned Sensitivity",
        "concepts": [
          "Limitations of axis-aligned splits",
          "Effect on model flexibility",
          "Handling correlated features"
        ]
      },
      {
        "topic": "Variance Issues",
        "concepts": [
          "High variance of deep trees",
          "Overfitting risks",
          "Ensemble methods to reduce variance"
        ]
      }
    ]
  },
  {
    "chapter": "Dimensionality Reduction",
    "topics": [
      {
        "topic": "Curse of Dimensionality",
        "concepts": [
          "Data sparsity in high dimensions",
          "Increased computational cost",
          "Difficulty in distance-based methods",
          "Overfitting risks"
        ]
      },
      {
        "topic": "Approaches to Dimensionality Reduction",
        "concepts": [
          "Projection methods",
          "Manifold learning",
          "Feature selection vs feature extraction"
        ]
      },
      {
        "topic": "Principal Component Analysis",
        "concepts": [
          "Variance preservation",
          "Principal components computation",
          "Projection onto d dimensions",
          "Using scikit-learn for PCA",
          "Explained variance ratio",
          "Choosing appropriate number of dimensions",
          "PCA for compression",
          "Randomized PCA",
          "Incremental PCA"
        ]
      },
      {
        "topic": "Random Projection",
        "concepts": [
          "Dimensionality reduction via random matrices",
          "Johnson-Lindenstrauss lemma",
          "Preserving pairwise distances"
        ]
      },
      {
        "topic": "Locally Linear Embedding",
        "concepts": [
          "Non-linear dimensionality reduction",
          "Manifold learning",
          "Preserving local neighborhood structure"
        ]
      },
      {
        "topic": "Other Dimensionality Reduction Techniques",
        "concepts": [
          "t-SNE",
          "Isomap",
          "Autoencoders",
          "Comparison of methods"
        ]
      }
    ]
  },
  {
    "chapter": "Introduction to Artificial Neural Networks with Keras",
    "topics": [
      {
        "topic": "From Biological Neurons to Artificial Neurons",
        "concepts": [
          "Structure of biological neurons",
          "Logical operations with neurons",
          "Perceptron model",
          "Multilayer perceptron and backpropagation",
          "MLP for regression tasks",
          "MLP for classification tasks"
        ]
      },
      {
        "topic": "Implementing MLPs with Keras",
        "concepts": [
          "Building image classifiers with Sequential API",
          "Loading datasets in Keras",
          "Creating models using Sequential API",
          "Compiling models",
          "Training, evaluating, and making predictions",
          "Creating regression MLPs",
          "Building complex models with Functional API",
          "Dynamic models using Subclassing API",
          "Saving and restoring models",
          "Using callbacks",
          "Visualization with TensorBoard"
        ]
      },
      {
        "topic": "Neural Network Hyperparameter Tuning",
        "concepts": [
          "Number of hidden layers",
          "Number of neurons per hidden layer",
          "Learning rate and batch size",
          "Other hyperparameters affecting training"
        ]
      }
    ]
  },
  {
    "chapter": "Sequence Processing with RNNs and CNNs",
    "topics": [
      {
        "topic": "Recurrent Neurons and Layers",
        "concepts": [
          "Memory cells in RNNs",
          "Handling input and output sequences",
          "State propagation across time steps"
        ]
      },
      {
        "topic": "Training RNNs",
        "concepts": [
          "Backpropagation through time",
          "Vanishing and exploding gradient challenges",
          "Optimization techniques for sequence models"
        ]
      },
      {
        "topic": "Time Series Prediction",
        "concepts": [
          "ARMA models for classical time series",
          "Preparing data for machine learning",
          "Linear models for sequence prediction",
          "Simple RNNs for forecasting",
          "Deep RNN architectures",
          "Multivariate time series prediction",
          "Predicting multiple future time steps",
          "Sequence-to-sequence models for forecasting"
        ]
      },
      {
        "topic": "Handling Long Sequences",
        "concepts": [
          "Fighting unstable gradients",
          "Solving short-term memory problems",
          "LSTM and GRU cells",
          "1D convolution layers for sequence processing",
          "WaveNet architecture"
        ]
      }
    ]
  }
]
